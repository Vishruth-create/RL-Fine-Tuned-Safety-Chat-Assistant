{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb05a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from trl.experimental.ppo import PPOConfig, PPOTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Configuration\n",
    "config = PPOConfig(\n",
    "    output_dir=\"./ppo-results\",\n",
    "    learning_rate=1.41e-5,\n",
    "    num_ppo_epochs=4,\n",
    "    kl_coef=0.05,\n",
    "    batch_size=128,\n",
    "    mini_batch_size=16,\n",
    "    bf16=False,\n",
    ")\n",
    "\n",
    "# 2. Model & Tokenizer Loading\n",
    "model_id = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the main model with Value Head\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_id)\n",
    "\n",
    "# --- THE FIX FOR THE ATTRIBUTE ERROR ---\n",
    "# Manually attach the generation_config from the internal model\n",
    "model.generation_config = model.pretrained_model.generation_config\n",
    "# ----------------------------------------\n",
    "\n",
    "# Load the 4 mandatory missing components for experimental trainer\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(model_id)\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "value_model = model # Use the existing WithValueHead model as the critic\n",
    "dataset = load_dataset(\"trl-lib/Capybara\", split=\"train[:128]\")\n",
    "\n",
    "# 3. Trainer Initialization\n",
    "ppo_trainer = PPOTrainer(\n",
    "    args=config,                # Argument 1\n",
    "    processing_class=tokenizer, # Argument 2\n",
    "    model=model,                # Argument 3\n",
    "    ref_model=ref_model,        # Argument 4\n",
    "    reward_model=reward_model,  # Argument 5\n",
    "    train_dataset=dataset,      # Argument 6\n",
    "    value_model=value_model     # Argument 7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
